---
title: "Uploading a Build"
description: "Upload a new build to Buildstash"
---

This guide covers uploading via single or multipart upload flows. Multipart is required for build files above 5GB, and optional for files smaller than this.

### Authorization

Note, a Buildstash app-level API key is required for uploading builds.

#### Request to start

<Steps>
  <Step title="Request to start upload" icon="chevron-right" stepNumber={1}>
    Use [/upload/request](/api-reference/endpoint/upload/request) endpoint to pass in all key build information, request to begin the upload process, and receive a presigned URL for uploading the build file to.

    <Card title="/upload/request" icon="terminal" horizontal href="/api-reference/endpoint/upload/request">
      
    </Card>
  </Step>
</Steps>

#### Upload - Single part

If your primary build file is smaller than 5GB you have the option to upload as a single part.

<Steps>
  <Step title="Upload file to presigned URL" icon="chevron-right" stepNumber={2}>
    Upload the file

    <CodeGroup dropdown expandable>

    ```bash Request
      # Assuming you've parsed the values from previous `uploadRequest.data` into environment variables
    curl -X PUT "$PRIMARY_FILE_URL" \
    --upload-file "$PRIMARY_FILE_PATH" \
    -H "Content-Type: $PRIMARY_FILE_CONTENT_TYPE" \
    -H "Content-Length: $PRIMARY_FILE_CONTENT_LENGTH" \
    -H "Content-Disposition: $PRIMARY_FILE_CONTENT_DISPOSITION" \
    -H "x-amz-acl: private"
    ```

    
    ```javascript Request
    // uploadRequest made as in above step
    const { pending_upload_id, primary_file, expansion_files } = uploadRequest.data;
    
    await axios.put(
      primary_file.presigned_data.url,
      fs.createReadStream(primaryFilePath),
      {
        headers: {
          'Content-Type': primary_file.presigned_data.headers['Content-Type'],
          'Content-Length': primary_file.presigned_data.headers['Content-Length'],
          'Content-Disposition': primary_file.presigned_data.headers['Content-Disposition'],
          'x-amz-acl': 'private'
        },
        maxBodyLength: Infinity
      }
    );
    ```

    
    ```python Request
    # uploadRequest made as in above step
    primary_file = uploadRequest["data"]["primary_file"]
    primaryFilePath = "path/to/your/file.exe"
    
    with open(primaryFilePath, "rb") as f:
        headers = {
            "Content-Type": primary_file["presigned_data"]["headers"]["Content-Type"],
            "Content-Length": primary_file["presigned_data"]["headers"]["Content-Length"],
            "Content-Disposition": primary_file["presigned_data"]["headers"]["Content-Disposition"],
            "x-amz-acl": "private"
        }
        response = requests.put(primary_file["presigned_data"]["url"], data=f, headers=headers)
    ```

    
    ```php Request
    // uploadRequest made as in above step
    $primary_file = $uploadRequest["data"]["primary_file"];
    $primaryFilePath = "path/to/your/file.exe";
    
    $file = fopen($primaryFilePath, "rb");
    $ch = curl_init($primary_file["presigned_data"]["url"]);
    curl_setopt($ch, CURLOPT_PUT, true);
    curl_setopt($ch, CURLOPT_INFILE, $file);
    curl_setopt($ch, CURLOPT_INFILESIZE, filesize($primaryFilePath));
    curl_setopt($ch, CURLOPT_HTTPHEADER, [
        "Content-Type: " . $primary_file["presigned_data"]["headers"]["Content-Type"],
        "Content-Length: " . $primary_file["presigned_data"]["headers"]["Content-Length"],
        "Content-Disposition: " . $primary_file["presigned_data"]["headers"]["Content-Disposition"],
        "x-amz-acl: private"
    ]);
    
    curl_exec($ch);
    curl_close($ch);
    fclose($file);
    ```

    
    ```go Request
    // uploadRequest made as in above step
    
    primaryFilePath := "path/to/your/file.exe"
    data := uploadRequest["data"].(map[string]interface{})
    primary := data["primary_file"].(map[string]interface{})
    presigned := primary["presigned_data"].(map[string]interface{})
    headers := presigned["headers"].(map[string]string)
    
    file, _ := os.Open(primaryFilePath)
    defer file.Close()
    
    req, _ := http.NewRequest("PUT", presigned["url"].(string), file)
    req.Header.Set("Content-Type", headers["Content-Type"])
    req.Header.Set("Content-Length", headers["Content-Length"])
    req.Header.Set("Content-Disposition", headers["Content-Disposition"])
    req.Header.Set("x-amz-acl", "private")
    
    client := &http.Client{}
    resp, _ := client.Do(req)
    defer resp.Body.Close()
    ```

    
    ```java Request
    // uploadRequest made as in above step
    
    String primaryFilePath = "path/to/your/file.exe";
    File file = new File(primaryFilePath);
    
    Map<String, Object> data = (Map<String, Object>) uploadRequest.get("data");
    Map<String, Object> primaryFile = (Map<String, Object>) data.get("primary_file");
    Map<String, Object> presigned = (Map<String, Object>) primaryFile.get("presigned_data");
    Map<String, String> headers = (Map<String, String>) presigned.get("headers");
    
    HttpURLConnection connection = (HttpURLConnection) new URL((String) presigned.get("url")).openConnection();
    connection.setDoOutput(true);
    connection.setRequestMethod("PUT");
    
    for (Map.Entry<String, String> header : headers.entrySet())
        connection.setRequestProperty(header.getKey(), header.getValue());
    connection.setRequestProperty("x-amz-acl", "private");
    
    try (OutputStream out = connection.getOutputStream();
         FileInputStream in = new FileInputStream(file)) {
        byte[] buffer = new byte[8192];
        int len;
        while ((len = in.read(buffer)) != -1)
            out.write(buffer, 0, len);
    }
    
    System.out.println("Response: " + connection.getResponseCode());
    ```

    
    ```csharp Request
    // uploadRequest made as in above step
    
    var primaryFilePath = "path/to/your/file.exe";
    var primary = uploadRequest.data.primary_file;
    var headers = primary.presigned_data.headers;
    
    using var stream = File.OpenRead(primaryFilePath);
    
    var request = new HttpRequestMessage(HttpMethod.Put, primary.presigned_data.url)
    {
        Content = new StreamContent(stream)
    };
    
    request.Content.Headers.ContentType = new MediaTypeHeaderValue(headers["Content-Type"]);
    request.Content.Headers.ContentLength = long.Parse(headers["Content-Length"]);
    request.Headers.Add("Content-Disposition", headers["Content-Disposition"]);
    request.Headers.Add("x-amz-acl", "private");
    
    var client = new HttpClient();
    var response = await client.SendAsync(request);
    ```

    
    ```ruby Request
    # uploadRequest made as in above step
    
    primary_file = uploadRequest[:data][:primary_file]
    primaryFilePath = "path/to/your/file.exe"
    uri = URI.parse(primary_file[:presigned_data][:url])
    
    request = Net::HTTP::Put.new(uri)
    headers = primary_file[:presigned_data][:headers]
    request["Content-Type"] = headers["Content-Type"]
    request["Content-Length"] = headers["Content-Length"]
    request["Content-Disposition"] = headers["Content-Disposition"]
    request["x-amz-acl"] = "private"
    request.body = File.read(primaryFilePath)
    
    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end
    
    puts response.code
    ```

    </CodeGroup>

    If the upload to S3 was successful, you've receive a response like:

    <CodeGroup>

    ```bash Response
    /HTTP/1.1 200 OK
    Date: Wed, 30 Jul 2025 20:48:28 GMT
    Content-Type: text/plain;charset=UTF-8
    Content-Length: 0
    Connection: keep-alive
    ETag: "a4d9c87f3e6b41c29fb2e7a8d1035b6e"
    x-amz-checksum-crc64nvme: H1KdR+1sY8c=
    x-amz-version-id: 93cf1f4e9e3d4ac2a8a4f929b03bd7a9
    Server: cloudflare
    CF-RAY: 9802ce3d5f6a1234-LAX
    ```

    </CodeGroup>

    Note the response may vary slightly depending on your S3 provider, for example AWS S3, Cloudflare R2, etc.
  </Step>
</Steps>

#### Upload - Multipart

Alternatively, if your primary build file is larger than 5GB, you must upload as multiple parts. Your original upload request will also return a chunked_upload boolean indicating whether multipart upload is advised and available for this build.

<Steps>
  <Step title="Request to start upload" icon="chevron-right" stepNumber={1}>
    Use [/upload/request/multipart](/api-reference/endpoint/upload/request-multipart) endpoint to request the presigned URL for each part.

    <Card title="/upload/request/multipart" icon="terminal" horizontal href="/api-reference/endpoint/upload/request-multipart">
      
    </Card>
  </Step>
  <Step title="Upload part" icon="chevron-right">
    For multipart uploads, once you have the presigned URL for each part, you'll need to upload that part, store returned ETag, and upload the next part, until all are complete. The provided examples demonstrate a relatively simple approach to this. Note more advanced approaches are possible including parallel uploads for efficiency.

    <CodeGroup dropdown expandable>

    ```bash Request
    # Set vars
    FILE="yourfile.bin"
    SIZE=$(stat -c %s "$FILE")
    CHUNK_SIZE_MB=5
    CHUNK_SIZE=$((CHUNK_SIZE_MB * 1024 * 1024))
    API_KEY="your_api_key"
    PENDING_ID="your_pending_upload_id"

    # Upload loop
    for i in $(seq 0 $(( (SIZE + CHUNK_SIZE - 1) / CHUNK_SIZE - 1))); do
      OFFSET=$((i * CHUNK_SIZE))
      PART_NUM=$((i + 1))
      LEN=$((CHUNK_SIZE))
      [ $((OFFSET + LEN)) -gt $SIZE ] && LEN=$((SIZE - OFFSET))

      echo "Uploading part $PART_NUM"

      PRESIGNED=$(curl -s -X POST https://app.buildstash.com/api/v1/upload/request/multipart \
        -H "Authorization: Bearer $API_KEY" \
        -H "Content-Type: application/json" \
        -d "{\"pending_upload_id\":\"$PENDING_ID\",\"part_number\":$PART_NUM,\"content_length\":$LEN}")

      URL=$(echo $PRESIGNED | jq -r .part_presigned_url)

      dd if="$FILE" bs=1 skip=$OFFSET count=$LEN 2>/dev/null | \
        curl -X PUT "$URL" -H "Content-Length: $LEN" -H "Content-Type: application/octet-stream" --data-binary @-
    done
    ```

    
    ```javascript Request
    // Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    async function uploadChunkedFile({
      filePath,
      filesize,
      pendingUploadId,
      chunkedNumberParts,
      chunkedPartSizeMb,
      apiKey,
    }) {
      // Read the file at filePath into a buffer
      const chunkSize = chunkedPartSizeMb * 1024 * 1024;
      const parts = [];

      // Loop through each part, get presigned URL, and upload it
      for (let i = 0; i < chunkedNumberParts; i++) {

        const chunkStart = i * chunkSize;
        const chunkEnd = Math.min((i + 1) * chunkSize - 1, filesize - 1);
        let chunkStream = fs.createReadStream(filePath, { start: chunkStart, end: chunkEnd });

        const contentLength = chunkEnd - chunkStart + 1;

        const partNumber = i + 1;

        core.info('Uploading chunked upload, part: ' + partNumber + ' of ' + chunkedNumberParts);

        // Request presigned URL for this part
        const presignedResp = await axios.post(
          'https://app.buildstash.com/api/v1/upload/request/multipart',
          {
            pending_upload_id: pendingUploadId,
            part_number: partNumber,
            content_length: contentLength
          },
          {
            headers: {
              'Authorization': Bearer ${apiKey},
              'Content-Type': 'application/json'
            }
          }
        );

        // Get presigned URL for this part from response
        const presignedUrl = presignedResp.data.part_presigned_url;

        // Upload chunk via presigned URL (on failure retry part once before error)
        let uploadResponse;
        let uploadError;
        // Attach error handler to the stream
        chunkStream.on('error', (err) => {
          core.error(File stream error for part ${partNumber}: ${err.message});
        });
        for (let attempt = 1; attempt <= 2; attempt++) {
          try {
            uploadResponse = await axios.put(
              presignedUrl,
              chunkStream,
              {
                headers: {
                  'Content-Type': 'application/octet-stream',
                  'Content-Length': contentLength
                },
                maxBodyLength: Infinity
              }
            );
            uploadError = null;
            break; // Success, exit retry loop
          } catch (err) {
            uploadError = err;
            // Log more error details
            if (err.response) {
              core.error(Chunk upload for part ${partNumber} failed (attempt ${attempt}): ${err.message}, status: ${err.response.status}, data: ${JSON.stringify(err.response.data)});
            } else {
              core.error(Chunk upload for part ${partNumber} failed (attempt ${attempt}): ${err.message});
            }
            if (attempt === 1) {
              // Re-create the stream for retry
              chunkStream.destroy();
            }
          }
          // If retrying, re-create the stream
          if (attempt === 1 && uploadError) {
            // Wait a short delay before retrying (optional, can be omitted or tuned)
            await new Promise(res => setTimeout(res, 500));
            // Re-create the stream for the retry
            chunkStream = fs.createReadStream(filePath, { start: chunkStart, end: chunkEnd });
            chunkStream.on('error', (err) => {
              core.error(File stream error for part ${partNumber} (retry): ${err.message});
            });
          }
        }
        if (uploadError) {
          throw uploadError;
        }
        // Check for ETag presence
        if (!uploadResponse.headers.etag) {
          core.warning(No ETag returned for part ${partNumber}. Response headers: ${JSON.stringify(uploadResponse.headers)});
        }

        // Add part to parts array
        parts.push({
          PartNumber: partNumber,
          ETag: uploadResponse.headers.etag
        });
      }

      // Return parts array
      return parts;
    }
    ```

    
    ```python Request
    # Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    def upload_chunked_file(path, filesize, pending_id, total_parts, part_mb, api_key):
        chunk_size = part_mb * 1024 * 1024
        parts = []
        with open(path, 'rb') as f:
            for i in range(total_parts):
                part_num = i + 1
                start = i * chunk_size
                end = min(start + chunk_size, filesize)
                f.seek(start)
                data = f.read(end - start)

                print(f"Uploading part {part_num}")

                res = requests.post(
                    "https://app.buildstash.com/api/v1/upload/request/multipart",
                    json={
                        "pending_upload_id": pending_id,
                        "part_number": part_num,
                        "content_length": len(data)
                    },
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    }
                )
                url = res.json()["part_presigned_url"]

                for attempt in range(2):
                    try:
                        upload = requests.put(url, data=data, headers={
                            "Content-Type": "application/octet-stream",
                            "Content-Length": str(len(data))
                        })
                        etag = upload.headers.get("ETag")
                        parts.append({"PartNumber": part_num, "ETag": etag})
                        break
                    except Exception as e:
                        print(f"Error part {part_num}, attempt {attempt+1}: {e}")
    return parts
    ```

    
    ```php Request
    use GuzzleHttp\Client;

    // Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    function uploadChunkedFile($filePath, $filesize, $pendingUploadId, $chunkedNumberParts, $chunkedPartSizeMb, $apiKey) {
        $chunkSize = $chunkedPartSizeMb * 1024 * 1024;
        $client = new Client();
        $parts = [];

        $file = fopen($filePath, 'rb');
        if (!$file) throw new Exception("Could not open file");

        for ($i = 0; $i < $chunkedNumberParts; $i++) {
            $chunkStart = $i * $chunkSize;
            $chunkEnd = min(($i + 1) * $chunkSize - 1, $filesize - 1);
            $contentLength = $chunkEnd - $chunkStart + 1;

            fseek($file, $chunkStart);
            $chunkData = fread($file, $contentLength);

            // Request presigned URL
            $response = $client->post('https://app.buildstash.com/api/v1/upload/request/multipart', [
                'headers' => [
                    'Authorization' => "Bearer $apiKey",
                    'Content-Type' => 'application/json'
                ],
                'json' => [
                    'pending_upload_id' => $pendingUploadId,
                    'part_number' => $i + 1,
                    'content_length' => $contentLength
                ]
            ]);
            $body = json_decode($response->getBody(), true);
            $presignedUrl = $body['part_presigned_url'];

            // Upload chunk
            $putResponse = $client->put($presignedUrl, [
                'headers' => [
                    'Content-Type' => 'application/octet-stream',
                    'Content-Length' => $contentLength
                ],
                'body' => $chunkData,
                'http_errors' => false, // handle errors yourself
            ]);

            if ($putResponse->getStatusCode() >= 400) {
                throw new Exception("Failed to upload part " . ($i + 1));
            }

            $etag = $putResponse->getHeaderLine('ETag');
            $parts[] = [
                'PartNumber' => $i + 1,
                'ETag' => $etag,
            ];
        }

        fclose($file);
        return $parts;
    }
    ```

    
    ```go Request
    // Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    func UploadChunked(path string, size int64, pendingId string, parts int, chunkMb int, apiKey string) {
      chunkSize := int64(chunkMb * 1024 * 1024)
      file, _ := os.Open(path)
      defer file.Close()

      for i := 0; i < parts; i++ {
        start := int64(i) * chunkSize
        end := start + chunkSize
        if end > size {
          end = size
        }
        partNum := i + 1
        fmt.Printf("Uploading part %d\n", partNum)

        // Request presigned URL
        body, _ := json.Marshal(map[string]interface{}{
          "pending_upload_id": pendingId,
          "part_number":       partNum,
          "content_length":    end - start,
        })
        req, _ := http.NewRequest("POST", "https://app.buildstash.com/api/v1/upload/request/multipart", bytes.NewBuffer(body))
        req.Header.Set("Authorization", "Bearer "+apiKey)
        req.Header.Set("Content-Type", "application/json")
        res, _ := http.DefaultClient.Do(req)
        defer res.Body.Close()
        var presigned struct{ URL string `json:"part_presigned_url"` }
        json.NewDecoder(res.Body).Decode(&presigned)

        // Upload chunk
        buf := make([]byte, end-start)
        file.ReadAt(buf, start)
        putReq, _ := http.NewRequest("PUT", presigned.URL, bytes.NewReader(buf))
        putReq.Header.Set("Content-Type", "application/octet-stream")
        putReq.ContentLength = int64(len(buf))
        http.DefaultClient.Do(putReq)
      }
    }
    ```

    
    ```java Request
    // Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    public class Uploader {
      public static void uploadChunked(String path, long filesize, String pendingId, int parts, int chunkMb, String apiKey) throws Exception {
        long chunkSize = chunkMb * 1024 * 1024;
        byte[] buffer = new byte[(int) chunkSize];
        try (RandomAccessFile file = new RandomAccessFile(path, "r")) {
          for (int i = 0; i < parts; i++) {
            int partNum = i + 1;
            long start = i * chunkSize;
            long len = Math.min(chunkSize, filesize - start);
            file.seek(start);
            file.readFully(buffer, 0, (int) len);

            System.out.println("Uploading part " + partNum);

            // Presigned URL
            URL url = new URL("https://app.buildstash.com/api/v1/upload/request/multipart");
            HttpURLConnection conn = (HttpURLConnection) url.openConnection();
            conn.setRequestMethod("POST");
            conn.setRequestProperty("Authorization", "Bearer " + apiKey);
            conn.setRequestProperty("Content-Type", "application/json");
            conn.setDoOutput(true);
            String json = String.format("{\"pending_upload_id\":\"%s\",\"part_number\":%d,\"content_length\":%d}", pendingId, partNum, len);
            conn.getOutputStream().write(json.getBytes());
            InputStream res = conn.getInputStream();
            String response = new String(res.readAllBytes());
            String presignedUrl = response.split("\"part_presigned_url\":\"")[1].split("\"")[0].replace("\\/", "/");

            // Upload chunk
            HttpURLConnection upload = (HttpURLConnection) new URL(presignedUrl).openConnection();
            upload.setDoOutput(true);
            upload.setRequestMethod("PUT");
            upload.setRequestProperty("Content-Type", "application/octet-stream");
            upload.setFixedLengthStreamingMode((int) len);
            upload.getOutputStream().write(buffer, 0, (int) len);
            upload.getInputStream().close();
          }
        }
      }
    }
    ```

    
    ```csharp Request
    // Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    async Task UploadChunked(string path, long filesize, string pendingId, int totalParts, int chunkMb, string apiKey)
    {
      var chunkSize = chunkMb * 1024 * 1024;
        using var file = File.OpenRead(path);
        var client = new HttpClient();
        for (int i = 0; i < totalParts; i++)
        {
            var partNum = i + 1;
            var start = i * chunkSize;
            var len = Math.Min(chunkSize, filesize - start);
            file.Seek(start, SeekOrigin.Begin);
            var buffer = new byte[len];
            file.Read(buffer, 0, (int)len);

            Console.WriteLine($"Uploading part {partNum}");

            var req = new
            {
                pending_upload_id = pendingId,
                part_number = partNum,
                content_length = len
            };
            var json = JsonSerializer.Serialize(req);
            var presigned = await client.PostAsync(
                "https://app.buildstash.com/api/v1/upload/request/multipart",
                new StringContent(json, Encoding.UTF8, "application/json")
            );
            var body = await presigned.Content.ReadAsStringAsync();
            var url = JsonDocument.Parse(body).RootElement.GetProperty("part_presigned_url").GetString();

            var put = new HttpRequestMessage(HttpMethod.Put, url)
            {
                Content = new ByteArrayContent(buffer)
            };
            put.Content.Headers.Add("Content-Type", "application/octet-stream");
            put.Content.Headers.Add("Content-Length", len.ToString());
            await client.SendAsync(put);
        }
    }
    ```

    
    ```ruby Request
    # Pass in values from initial upload request, and get parts etags back to use for verifying upload completion later
    def upload_chunked_file(path, filesize, pending_id, total_parts, chunk_mb, api_key)
      chunk_size = chunk_mb * 1024 * 1024
      parts = []
      File.open(path, 'rb') do |file|
        total_parts.times do |i|
          part_num = i + 1
          start = i * chunk_size
          file.seek(start)
          data = file.read([chunk_size, filesize - start].min)

          puts "Uploading part #{part_num}"

          uri = URI("https://app.buildstash.com/api/v1/upload/request/multipart")
          presigned = Net::HTTP.post(uri,
            { pending_upload_id: pending_id, part_number: part_num, content_length: data.length }.to_json,
            { "Authorization" => "Bearer #{api_key}", "Content-Type" => "application/json" })
          url = JSON.parse(presigned.body)["part_presigned_url"]

          uri = URI(url)
          resp = Net::HTTP.start(uri.host, uri.port, use_ssl: true) do |http|
            req = Net::HTTP::Put.new(uri)
            req['Content-Type'] = 'application/octet-stream'
            req.body = data
            http.request(req)
          end

          etag = resp['etag']
          parts << { PartNumber: part_num, ETag: etag }
        end
      end
      parts
    end
    ```

    </CodeGroup>

    If the upload to S3 was successful, you'll receive a response including the ETag for that part - which is the critical information for verifying the upload later.

    You'll want to create an object pairing each part number with the accompanying ETag in order to verify the upload later.

    <CodeGroup>

    ```bash Response
    HTTP/1.1 200 OK
    x-amz-id-2: ...
    x-amz-request-id: ...
    ETag: "9b2cf535f27731c974343645a3985328"
    Date: Wed, 21 Jul 2021 17:20:40 GMT
    Content-Length: 0
    ```

    </CodeGroup>
    
  </Step>
</Steps>

#### Expansion upload

In addition to your primary build file, you may also optionally upload an expansion file, where this is supported by the target platform on Buildstash. An example of this is uploading an OBB expansion file to accompany a primary APK.

<Steps>
  <Step title="Include expansion file details in initial start upload request" icon="chevron-right" stepNumber={1}>
    When you call [/upload/request](/api-reference/endpoint/upload/request) endpoint in the first step, you'll include the expansion file details there, and receive the presigned URL to upload to, similarly to with the primary file.
  </Step>

  <Step title="Upload expansion file" icon="chevron-right" stepNumber={2}>
    Upload your expansion file, using the same logic as with the primary file. Remember to not call /upload/verify until both primary and expansion files are uploaded.
  </Step>
</Steps>

#### Verify and complete

<Steps>
  <Step title="Verify and complete upload" icon="chevron-right" stepNumber={4}>
    Once all files are uploaded, use [/upload/verify](/api-reference/endpoint/upload/verify) endpoint to inform Buildstash the upload is complete, validate all parts have successfully uploaded, and complete the upload flow. Once you receive a successful response from the endpoint, the build will be available in the Buildstash interface!

    <Card title="/upload/verify" icon="terminal" horizontal href="/api-reference/endpoint/upload/verify">

    </Card>

    Note, for some build types where additional server side processing is required (for example iOS and Android builds), the verify endpoint will return the pending_processing boolean as true. In this case there will be a small delay before the build is available for download.
  </Step>
</Steps>

### Best practices

1. **Retry Logic**: Implement retry logic for failed S3 file uploads
2. **Progress Tracking**: Track upload progress for each part of large files
3. **Parallel Uploads**: Upload parts in parallel for better performance
4. **Cleanup**: Handle cleanup on upload failure

### Provided integrations

<Card title="CI Integrations" href="https://support.buildstash.com/docs">
  We provide a number of off-the-shelf integrations for uploading builds to Buildstash via widely used CI platforms - like GitHub Actions and Azure Pipelines.
</Card>